# -*- coding: utf-8 -*-
"""ie534_hw4_pretrained_cifar100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13234iFTipZTlmsVGoqTKsYAtvH-l2SRG
"""

import torchvision
import torch
from torch.utils import model_zoo
from torch.nn.functional import interpolate
import torchvision.transforms as transforms
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
import torch.backends.cudnn as cudnn


import time
import matplotlib.pyplot as plt

model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',
    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',
    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',
    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',
}

def resnet18(pretrained=True):
    model = torchvision.models.resnet.ResNet(torchvision.models.resnet.BasicBlock, [2,2,2,2])
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet18'], model_dir='./'))
    return model

model = resnet18(pretrained=True)

# The input size for the pre-trained model is 224*224 so have to up-sample the images in CIFAR100 dataset.
pretrained_size = 224
scale_factor = 224/32

# data augmentation
train_transform = transforms.Compose(
    [transforms.Resize(size=(224, 224)),
     transforms.RandomCrop(224, padding=4),
     transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
     transforms.Normalize(mean= [0.50707516,0.48654887,0.44091784], std=[0.26733429,0.25643846,0.27615047])])

test_transform = transforms.Compose([transforms.Resize(size=(224, 224)),transforms.ToTensor(),
     transforms.Normalize(mean= [0.50707516,0.48654887,0.44091784], std=[0.26733429,0.25643846,0.27615047])])

# For trainning data
trainset = torchvision.datasets.CIFAR100(root='./data',
train=True,download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset,
batch_size=100, shuffle=True, num_workers=8)
# For testing data
testset = torchvision.datasets.CIFAR100(root='./data',
train=False,download=True, transform=test_transform)
testloader = torch.utils.data.DataLoader(testset,
batch_size=100, shuffle=False, num_workers=8)

model = torch.nn.Sequential(model, torch.nn.Linear(model.fc.out_features, 100))

model.cuda()
model = nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))
cudnn.benchmark=True
criterion=nn.CrossEntropyLoss()
optimizer=optim.Adam(model.parameters())

best_test_accuracy = 0.0
test_accuracy_list = []

start = time.time()
for epoch in range(70):
    running_loss = 0.0
    model.train()
    for i, data in enumerate(trainloader, 0): # Reference: https://zhuanlan.zhihu.com/p/42501145
        inputs, labels = data
        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        # fixed IndexError: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number
        running_loss+=loss.item()

        if i % 2000 == 1999:
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
        
    correct = 0
    total = 0
    model.eval()
    for j, data in enumerate(testloader, 0):

        inputs, labels = data
        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        correct += predicted.eq(labels).float().sum().item()
        total += len(labels)

    test_accuracy_list.append(correct/total)

    print(f'accuracy every epoch {(correct/total):.3f}')
    if correct/total > best_test_accuracy:
        best_test_accuracy = correct/total

        
end = time.time()
print('Total training time:', end-start)
print('The best test accuracy is', best_test_accuracy)

plt.plot(list(range(len(test_accuracy_list))), test_accuracy_list)
plt.xlabel('epochs')
plt.ylabel('test_accuracy')
plt.title('learning curve plot')
plt.show()

model.eval()
correct = 0
total =  0 

for i, data in enumerate(testloader, 0):
    inputs, labels = data
    inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
    outputs = model(inputs)

    _, predicted = torch.max(outputs.data, 1)
    correct += predicted.eq(labels).float().sum().item()
    total += len(labels)

print(f'accuracy on test set {(correct/total):.3f}')

