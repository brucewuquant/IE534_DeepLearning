# -*- coding: utf-8 -*-
"""hw2_dizhou_wu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YBMX6HdsJacaZVD2XH00wHEAk-sWVYET
"""

# from google.colab import drive
# drive.mount('/content/drive')

import os

# os.chdir('/content/drive/My Drive/UIUC Course/IE534')

"""HW3: Train a deep convolution network on a GPU with PyTorch for the CIFAR10 dataset. The convolution network should use (A) dropout, (B) trained with RMSprop or ADAM, and (C) data augmentation. For 10% extra credit, compare dropout test accuracy (i) using the heuristic prediction rule and (ii) Monte Carlo simulation. For full credit, the model should achieve 80-90% Test Accuracy. Submit via Compass (1) the code and (2) a paragraph (in a PDF document) which reports the results and briefly describes the model architecture. Due September 28 at 5:00 PM."""

import h5py
import copy
import time
import numpy as np


import torchvision, torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torch.optim as optim
import torch.backends.cudnn as cudnn

CIFAR10_data = h5py.File('./data/CIFAR10.hdf5', 'r')
x_train = np.float32(CIFAR10_data['X_train'][:])
y_train = np.int32(np.array(CIFAR10_data['Y_train']))
x_test = np.float32(CIFAR10_data['X_test'][:])
y_test = np.int32(np.array(CIFAR10_data['Y_test']))
CIFAR10_data.close()

x_train.shape

# get the statistic needed at the transform stage
means = []
stds = []
for i in range(3):
    pixels = x_train[:,i,:,:].ravel()
    means.append(np.mean(pixels))
    stds.append(np.std(pixels))
print(means)
print(stds)

# Commented out IPython magic to ensure Python compatibility.
from matplotlib.pyplot import imshow
from PIL import Image

# %matplotlib inline
pil_im = Image.open('./vgg16.png', 'r')
imshow(np.asarray(pil_im))

# data augmentation
train_transform = transforms.Compose(
    [transforms.RandomCrop(32, padding=4),
     transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
     transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))])

test_transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=4)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=test_transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=4)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

class CNN(nn.Module):

    def __init__(self):

        super(CNN, self).__init__()

        self.conv = nn.Sequential(

            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),
#             nn.BatchNorm2d(64),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(kernel_size=2, stride=2),
            

            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            
#             nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
#             nn.BatchNorm2d(128),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
#             nn.BatchNorm2d(256),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(kernel_size=2, stride=2),
            

            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
#             nn.BatchNorm2d(512),
#             nn.ReLU(inplace=True),
#             nn.MaxPool2d(kernel_size=2, stride=2)
            
        )


        self.fc = nn.Sequential(
            nn.Dropout(p=0.2),
            nn.Linear(2048, 1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.2),
            nn.Linear(512, 10)
        )


    def forward(self, x):

        x = self.conv(x)
        
        # flatten to fc
        x = x.view(x.size(0), -1)
        
        x = self.fc(x)

        return x

cnn_hw3 = CNN()
cuda_flag = torch.cuda.is_available()
if cuda_flag:
    cnn_hw3.cuda()
    net = nn.DataParallel(cnn_hw3, device_ids = range(torch.cuda.device_count()))
    cudnn.benchmark = True

from torchsummary import summary
summary(cnn_hw3, input_size=(3, 32, 32))

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters())

net.train()
start = time.time()

for epoch in range(50):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0): # Reference: https://zhuanlan.zhihu.com/p/42501145
        inputs, labels = data
        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        # fixed IndexError: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number
        running_loss+=loss.item()

        if i % 2000 == 1999:
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
        
    if epoch % 20 == 0:
        correct = 0
        total = 0
        for j, data in enumerate(trainloader, 0):
            inputs, labels = data
            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
            outputs = net(inputs)
            _, predicted = torch.max(outputs.data, 1)
            correct += predicted.eq(labels).float().sum().item()
            total += len(labels)
        print(f'accuracy every 20 epochs {(correct/total):.3f}')

        
end = time.time()
print('Total training time:', end-start)

net.eval()
correct = 0
total =  0 

for i, data in enumerate(testloader, 0):
    inputs, labels = data
    inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()
    outputs = net(inputs)

    _, predicted = torch.max(outputs.data, 1)
    correct += predicted.eq(labels).float().sum().item()
    total += len(labels)

print(f'accuracy on test set {(correct/total):.3f}')

